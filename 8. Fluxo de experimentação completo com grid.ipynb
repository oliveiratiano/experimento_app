{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando arquivo corpus. Por favor aguarde.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corpus_tratado.zip: 150MB [00:12, 12.3MB/s]                            \n",
      "Extraindo corpus: 100%|██████████| 40013/40013 [00:24<00:00, 1634.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtrando assuntos com frequencia minima 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:00<00:00, 518.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtrando assuntos com no minimo 50 palavras\n",
      "total de documentos no corpus: 168\n"
     ]
    }
   ],
   "source": [
    "from src import transformer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "transformer.extrair_corpus()\n",
    "documentos_validos = transformer.ler_documentos_validos(quantidade=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do fluxo de experimentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tesauro_stf.csv: 2.03MB [00:00, 4.94MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando arquivo w2v_skip_nilc.txt. Por favor aguarde.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w2v_skip_nilc.txt: 895MB [01:19, 11.2MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importando w2v geral\n",
      "Baixando arquivo ftt_skip_nilc.txt. Por favor aguarde.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftt_skip_nilc.txt: 100%|█████████▉| 812M/812M [01:09<00:00, 11.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importando ftt geral\n",
      "Baixando arquivo glove_nilc.txt. Por favor aguarde.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glove_nilc.txt: 100%|█████████▉| 894M/895M [01:21<00:00, 11.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importando glv geral\n",
      "----------------------- EXPERIMENTO __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 -----------------------\n",
      "criando base de treino para o experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 2358.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24011 tokens copiados com sucesso\n",
      "preparando documentos para extração do vocabulário:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 13372.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraindo termos com base no ICA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 752.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-processando strings do corpus\n",
      "-treinando vetorizador\n",
      "-ICA processado\n",
      "extraindo termos com base na frequência - geralmente leva menos de 4 minutos\n",
      "extraindo termos do tesauro\n",
      "***************extração de vocabulário concluída: 5894 palavras******************\n",
      "treinando modelo glove\n",
      "mkdir -p build\n",
      "tokenizando corpus\n",
      "$ build/vocab_count -min-count 5 -verbose 2 < ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/base_treino_glv.txt > ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glove_vocab.txt\n",
      "criando matriz de coocorrencia\n",
      "$ build/cooccur -memory 4.0 -vocab-file ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glove_vocab.txt -verbose 2 -window-size 15 < ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/base_treino_glv.txt > ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glv_concurrence.bin\n",
      "$ build/shuffle -memory 4.0 -verbose 2 < ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glv_concurrence.bin > ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glv_concurrence_shuf.bin\n",
      "$ build/glove -save-file ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glv_jur -threads 8 -input-file ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glv_concurrence_shuf.bin -x-max 10 -iter 15 -vector-size 100 -binary 2 -vocab-file ../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glove_vocab.txt -verbose 2\n",
      "\n",
      "BUILDING VOCABULARY\n",
      "Processed 0 tokens.Processed 14942 tokens.\n",
      "Counted 2449 unique words.\n",
      "Truncating vocabulary at min count 5.\n",
      "Using vocabulary of size 460.\n",
      "\n",
      "COUNTING COOCCURRENCES\n",
      "window size: 15\n",
      "context: symmetric\n",
      "max product: 13752509\n",
      "overflow length: 38028356\n",
      "Reading vocab from file \"../dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/glove_vocab.txt\"...loaded 460 words.\n",
      "Building lookup table...table contains 211601 elements.\n",
      "Processing token: 0Processed 14942 tokens.\n",
      "Writing cooccurrences to disk.....2 files in total.\n",
      "Merging cooccurrence files: processed 0 lines.0 lines.Merging cooccurrence files: processed 50124 lines.\n",
      "\n",
      "Using random seed 1618644429\n",
      "SHUFFLING COOCCURRENCES\n",
      "array size: 255013683\n",
      "Shuffling by chunks: processed 0 lines.processed 50124 lines.\n",
      "Wrote 1 temporary file(s).\n",
      "Merging temp files: processed 0 lines.50124 lines.Merging temp files: processed 50124 lines.\n",
      "\n",
      "TRAINING MODEL\n",
      "Read 50124 lines.\n",
      "Initializing parameters...Using random seed 1618644429\n",
      "done.\n",
      "vector size: 100\n",
      "vocab size: 460\n",
      "x_max: 10.000000\n",
      "alpha: 0.750000\n",
      "04/17/21 - 04:27.09AM, iter: 001, cost: 0.141649\n",
      "04/17/21 - 04:27.09AM, iter: 002, cost: 0.113608\n",
      "04/17/21 - 04:27.10AM, iter: 003, cost: 0.110591\n",
      "04/17/21 - 04:27.10AM, iter: 004, cost: 0.108729\n",
      "04/17/21 - 04:27.10AM, iter: 005, cost: 0.106769\n",
      "04/17/21 - 04:27.10AM, iter: 006, cost: 0.102079\n",
      "04/17/21 - 04:27.10AM, iter: 007, cost: 0.095344\n",
      "04/17/21 - 04:27.10AM, iter: 008, cost: 0.088664\n",
      "04/17/21 - 04:27.10AM, iter: 009, cost: 0.082109\n",
      "04/17/21 - 04:27.10AM, iter: 010, cost: 0.075472\n",
      "04/17/21 - 04:27.10AM, iter: 011, cost: 0.069068\n",
      "04/17/21 - 04:27.10AM, iter: 012, cost: 0.063150\n",
      "04/17/21 - 04:27.10AM, iter: 013, cost: 0.058002\n",
      "04/17/21 - 04:27.10AM, iter: 014, cost: 0.053604\n",
      "04/17/21 - 04:27.10AM, iter: 015, cost: 0.049901\n",
      "\n",
      "treinamento concluído\n",
      "treinando modelo word2vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-17 04:27:10,300 : INFO : collecting all words and their counts\n",
      "2021-04-17 04:27:10,307 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-04-17 04:27:10,314 : INFO : collected 2550 word types from a corpus of 22954 raw words and 1038 sentences\n",
      "2021-04-17 04:27:10,315 : INFO : Loading a fresh vocabulary\n",
      "2021-04-17 04:27:10,318 : INFO : effective_min_count=5 retains 522 unique words (20% of original 2550, drops 2028)\n",
      "2021-04-17 04:27:10,318 : INFO : effective_min_count=5 leaves 19862 word corpus (86% of original 22954, drops 3092)\n",
      "2021-04-17 04:27:10,321 : INFO : deleting the raw counts dictionary of 2550 items\n",
      "2021-04-17 04:27:10,321 : INFO : sample=1e-05 downsamples 522 most-common words\n",
      "2021-04-17 04:27:10,322 : INFO : downsampling leaves estimated 1216 word corpus (6.1% of prior 19862)\n",
      "2021-04-17 04:27:10,323 : INFO : constructing a huffman tree from 522 words\n",
      "2021-04-17 04:27:10,332 : INFO : built huffman tree with maximum node depth 12\n",
      "2021-04-17 04:27:10,333 : INFO : estimated required memory for 522 words and 100 dimensions: 991800 bytes\n",
      "2021-04-17 04:27:10,334 : INFO : resetting layer weights\n",
      "2021-04-17 04:27:10,417 : INFO : training model with 12 workers on 522 vocabulary and 100 features, using sg=1 hs=1 sample=1e-05 negative=5 window=5\n",
      "2021-04-17 04:27:10,433 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,435 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,435 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,436 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,437 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,438 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,438 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,439 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,440 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,440 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,442 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,443 : INFO : EPOCH - 1 : training on 22954 raw words (1202 effective words) took 0.0s, 59864 effective words/s\n",
      "2021-04-17 04:27:10,455 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,457 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,458 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,459 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,460 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,461 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,461 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,462 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,465 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,465 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,466 : INFO : EPOCH - 2 : training on 22954 raw words (1281 effective words) took 0.0s, 70049 effective words/s\n",
      "2021-04-17 04:27:10,478 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,480 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,481 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,482 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,482 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,483 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,484 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,485 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,485 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,486 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,487 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,488 : INFO : EPOCH - 3 : training on 22954 raw words (1208 effective words) took 0.0s, 65640 effective words/s\n",
      "2021-04-17 04:27:10,500 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,503 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,503 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,504 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,505 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,505 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,506 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,507 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,508 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,508 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,511 : INFO : EPOCH - 4 : training on 22954 raw words (1173 effective words) took 0.0s, 65673 effective words/s\n",
      "2021-04-17 04:27:10,523 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,525 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,526 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,526 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,527 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,528 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,529 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,529 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,530 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,533 : INFO : EPOCH - 5 : training on 22954 raw words (1188 effective words) took 0.0s, 64370 effective words/s\n",
      "2021-04-17 04:27:10,545 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,547 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,548 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,549 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,550 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,550 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,551 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,552 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,553 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-17 04:27:10,553 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,554 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,556 : INFO : EPOCH - 6 : training on 22954 raw words (1199 effective words) took 0.0s, 66008 effective words/s\n",
      "2021-04-17 04:27:10,567 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,569 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,570 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,571 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,571 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,572 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,573 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,574 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,574 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,575 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,576 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,577 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,578 : INFO : EPOCH - 7 : training on 22954 raw words (1162 effective words) took 0.0s, 65128 effective words/s\n",
      "2021-04-17 04:27:10,590 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,591 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,592 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,593 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,594 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,595 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,595 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,596 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,597 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,599 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,600 : INFO : EPOCH - 8 : training on 22954 raw words (1220 effective words) took 0.0s, 66011 effective words/s\n",
      "2021-04-17 04:27:10,612 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,615 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,616 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,616 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,617 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,618 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,619 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,619 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,620 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,621 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,622 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,623 : INFO : EPOCH - 9 : training on 22954 raw words (1255 effective words) took 0.0s, 68209 effective words/s\n",
      "2021-04-17 04:27:10,636 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:10,638 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:10,639 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:10,639 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:10,640 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:10,641 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:10,641 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:10,642 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:10,643 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:10,644 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:10,644 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:10,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:10,646 : INFO : EPOCH - 10 : training on 22954 raw words (1217 effective words) took 0.0s, 64425 effective words/s\n",
      "2021-04-17 04:27:10,647 : INFO : training on a 229540 raw words (12105 effective words) took 0.2s, 52940 effective words/s\n",
      "2021-04-17 04:27:10,648 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-04-17 04:27:10,649 : INFO : saving Word2Vec object under dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/w2v_jur.model, separately None\n",
      "2021-04-17 04:27:10,650 : INFO : not storing attribute vectors_norm\n",
      "2021-04-17 04:27:10,651 : INFO : not storing attribute cum_table\n",
      "2021-04-17 04:27:10,660 : INFO : saved dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/w2v_jur.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando modelo fasttext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-17 04:27:10,662 : INFO : resetting layer weights\n",
      "2021-04-17 04:27:14,709 : INFO : collecting all words and their counts\n",
      "2021-04-17 04:27:14,710 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-04-17 04:27:14,717 : INFO : collected 2550 word types from a corpus of 22954 raw words and 1038 sentences\n",
      "2021-04-17 04:27:14,718 : INFO : Loading a fresh vocabulary\n",
      "2021-04-17 04:27:14,720 : INFO : effective_min_count=5 retains 522 unique words (20% of original 2550, drops 2028)\n",
      "2021-04-17 04:27:14,721 : INFO : effective_min_count=5 leaves 19862 word corpus (86% of original 22954, drops 3092)\n",
      "2021-04-17 04:27:14,723 : INFO : deleting the raw counts dictionary of 2550 items\n",
      "2021-04-17 04:27:14,724 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2021-04-17 04:27:14,725 : INFO : downsampling leaves estimated 12132 word corpus (61.1% of prior 19862)\n",
      "2021-04-17 04:27:14,726 : INFO : constructing a huffman tree from 522 words\n",
      "2021-04-17 04:27:14,734 : INFO : built huffman tree with maximum node depth 12\n",
      "2021-04-17 04:27:14,739 : INFO : estimated required memory for 522 words, 6367 buckets and 100 dimensions: 3648600 bytes\n",
      "2021-04-17 04:27:14,740 : INFO : resetting layer weights\n",
      "2021-04-17 04:27:16,960 : INFO : training model with 12 workers on 522 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2021-04-17 04:27:17,010 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:17,061 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:17,119 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:17,166 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:17,199 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:17,205 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:17,208 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:17,213 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:17,215 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:17,216 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:17,219 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:17,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:17,222 : INFO : EPOCH - 1 : training on 98735 raw words (53007 effective words) took 0.2s, 213705 effective words/s\n",
      "2021-04-17 04:27:17,270 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:17,318 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:17,368 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:17,425 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:17,442 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:17,467 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:17,471 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:17,473 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:17,474 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:17,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:17,480 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:17,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:17,483 : INFO : EPOCH - 2 : training on 98735 raw words (52941 effective words) took 0.3s, 209484 effective words/s\n",
      "2021-04-17 04:27:17,532 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:17,582 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:17,641 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:17,686 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:17,720 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:17,728 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:17,730 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:17,733 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:17,739 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:17,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:17,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:17,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:17,752 : INFO : EPOCH - 3 : training on 98735 raw words (53091 effective words) took 0.3s, 205148 effective words/s\n",
      "2021-04-17 04:27:17,797 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:17,851 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:17,899 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:17,961 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:17,994 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:18,004 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:18,015 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:18,016 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:18,018 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:18,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:18,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:18,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:18,028 : INFO : EPOCH - 4 : training on 98735 raw words (52889 effective words) took 0.3s, 198247 effective words/s\n",
      "2021-04-17 04:27:18,110 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-04-17 04:27:18,137 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-04-17 04:27:18,198 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-17 04:27:18,241 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-17 04:27:18,293 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:18,302 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:18,306 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:18,308 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:18,311 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:18,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:18,316 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:18,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:18,318 : INFO : EPOCH - 5 : training on 98735 raw words (52979 effective words) took 0.3s, 189029 effective words/s\n",
      "2021-04-17 04:27:18,319 : INFO : training on a 493675 raw words (264907 effective words) took 1.4s, 195224 effective words/s\n",
      "2021-04-17 04:27:18,320 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-04-17 04:27:18,340 : INFO : saving FastText object under dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/ftt_jur.model, separately None\n",
      "2021-04-17 04:27:18,341 : INFO : storing np array 'vectors_ngrams' to dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/ftt_jur.model.wv.vectors_ngrams.npy\n",
      "2021-04-17 04:27:25,173 : INFO : not storing attribute vectors_norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-17 04:27:25,175 : INFO : not storing attribute vectors_vocab_norm\n",
      "2021-04-17 04:27:25,176 : INFO : not storing attribute vectors_ngrams_norm\n",
      "2021-04-17 04:27:25,177 : INFO : not storing attribute buckets_word\n",
      "2021-04-17 04:27:25,178 : INFO : storing np array 'vectors_ngrams_lockf' to dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/ftt_jur.model.trainables.vectors_ngrams_lockf.npy\n",
      "2021-04-17 04:27:32,291 : INFO : saved dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/ftt_jur.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recuperando teores da base de teste\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 11364.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criando representações word2vec geral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 1620.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criando representações fasttext geral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 1482.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criando representações glove geral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 1547.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criando representações word2vec juridico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 3242.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criando representações fasttext juridico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 1794.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criando representações glove juridico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 1549.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo do experimento: 8.330938827991485 minutos\n",
      "--------- Treinando doc2vec do experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-17 04:27:32,591 : INFO : collecting all words and their counts\n",
      "2021-04-17 04:27:32,592 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-04-17 04:27:32,596 : INFO : collected 2449 word types and 134 unique tags from a corpus of 134 examples and 14942 words\n",
      "2021-04-17 04:27:32,597 : INFO : Loading a fresh vocabulary\n",
      "2021-04-17 04:27:32,600 : INFO : effective_min_count=1 retains 2449 unique words (100% of original 2449, drops 0)\n",
      "2021-04-17 04:27:32,601 : INFO : effective_min_count=1 leaves 14942 word corpus (100% of original 14942, drops 0)\n",
      "2021-04-17 04:27:32,607 : INFO : deleting the raw counts dictionary of 2449 items\n",
      "2021-04-17 04:27:32,608 : INFO : sample=0.001 downsamples 82 most-common words\n",
      "2021-04-17 04:27:32,609 : INFO : downsampling leaves estimated 11617 word corpus (77.8% of prior 14942)\n",
      "2021-04-17 04:27:32,613 : INFO : estimated required memory for 2449 words and 100 dimensions: 3237300 bytes\n",
      "2021-04-17 04:27:32,614 : INFO : resetting layer weights\n",
      "2021-04-17 04:27:33,030 : INFO : training model with 8 workers on 2449 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-04-17 04:27:33,039 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:33,042 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:33,044 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:33,045 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:33,047 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:33,048 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:33,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:33,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:33,050 : INFO : EPOCH - 1 : training on 16439 raw words (13062 effective words) took 0.0s, 1132527 effective words/s\n",
      "2021-04-17 04:27:33,059 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:33,061 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:33,063 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:33,065 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:33,066 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:33,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:33,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:33,069 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:33,069 : INFO : EPOCH - 2 : training on 16439 raw words (13023 effective words) took 0.0s, 1148929 effective words/s\n",
      "2021-04-17 04:27:33,078 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:33,081 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:33,082 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:33,085 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:33,087 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:33,088 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:33,089 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:33,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:33,091 : INFO : EPOCH - 3 : training on 16439 raw words (13048 effective words) took 0.0s, 995689 effective words/s\n",
      "2021-04-17 04:27:33,099 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:33,103 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:33,104 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:33,106 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:33,107 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:33,109 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:33,109 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:33,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:33,111 : INFO : EPOCH - 4 : training on 16439 raw words (13086 effective words) took 0.0s, 1110093 effective words/s\n",
      "2021-04-17 04:27:33,119 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-17 04:27:33,122 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-17 04:27:33,123 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-17 04:27:33,125 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-17 04:27:33,126 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-17 04:27:33,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-17 04:27:33,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-17 04:27:33,129 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-17 04:27:33,129 : INFO : EPOCH - 5 : training on 16439 raw words (13095 effective words) took 0.0s, 1312216 effective words/s\n",
      "2021-04-17 04:27:33,130 : INFO : training on a 82195 raw words (65314 effective words) took 0.1s, 659854 effective words/s\n",
      "2021-04-17 04:27:33,131 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-04-17 04:27:33,132 : INFO : saving Doc2Vec object under dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/doc2vec_jur.model, separately None\n",
      "2021-04-17 04:27:33,149 : INFO : saved dados/experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208/doc2vec_jur.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Inferindo vetores para docs de teste do experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "--------- Agrupando dados para o modelo vec_w2v_ger_soma no experimento__minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- executando analyzer para experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "calculando matriz de similaridade nos vetores vec_w2v_ger_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 811.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando a similaridade entre assuntos para o modelo vec_w2v_ger_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 376.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Agrupando dados para o modelo vec_ftt_ger_soma no experimento__minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 65.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- executando analyzer para experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "calculando matriz de similaridade nos vetores vec_ftt_ger_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 830.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando a similaridade entre assuntos para o modelo vec_ftt_ger_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 374.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Agrupando dados para o modelo vec_glv_ger_soma no experimento__minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 56.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- executando analyzer para experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "calculando matriz de similaridade nos vetores vec_glv_ger_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 831.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando a similaridade entre assuntos para o modelo vec_glv_ger_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 376.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Agrupando dados para o modelo vec_w2v_jur_soma no experimento__minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 57.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- executando analyzer para experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "calculando matriz de similaridade nos vetores vec_w2v_jur_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 851.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando a similaridade entre assuntos para o modelo vec_w2v_jur_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 375.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Agrupando dados para o modelo vec_ftt_jur_soma no experimento__minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 68.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- executando analyzer para experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "calculando matriz de similaridade nos vetores vec_ftt_jur_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 852.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando a similaridade entre assuntos para o modelo vec_ftt_jur_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 377.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Agrupando dados para o modelo vec_glv_jur_soma no experimento__minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 77.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- executando analyzer para experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "calculando matriz de similaridade nos vetores vec_glv_jur_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 830.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando a similaridade entre assuntos para o modelo vec_glv_jur_soma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 374.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Agrupando dados para o modelo doc2vec_jur no experimento__minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 61.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- executando analyzer para experimento __minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__seed-208 ---------\n",
      "calculando matriz de similaridade nos vetores doc2vec_jur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 853.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando a similaridade entre assuntos para o modelo doc2vec_jur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 429.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- EXPERIMENTO COM SEED 208 CONCLUIDO -----------\n"
     ]
    }
   ],
   "source": [
    "lista_k = np.arange(2,5)\n",
    "grid_minfreqs = [0]\n",
    "grid_stopwords = [True]\n",
    "grid_ica = [True]\n",
    "grid_tesauro = [True]\n",
    "grid_dimensoes = [100]\n",
    "df = transformer.transform_param(documentos_validos, grid_minfreqs, grid_stopwords, grid_ica, grid_tesauro, grid_dimensoes, lista_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
